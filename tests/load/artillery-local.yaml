config:
  target: "http://localhost:5000"
  plugins:
    ensure: {}
  ensure:
    thresholds:
      - "http.response_time.p95": 500
    conditions:
      - expression: "http.codes.200 / http.requests > 0.95"
  environments:
    functional:
      phases:
        - name: functional_test
          duration: 1
          arrivalCount: 1
      plugins:
        expect:
          formatter: "pretty"
          expectDefault200: true
          reportFailuresAsErrors: true
          useOnlyRequestNames: true
      ensure:
        thresholds:
          - "http.response_time.p95": 300
        conditions:
          - expression: "http.codes.200 / http.requests > 0.99"
    load:
      phases:
        - name: load_test
          duration: 60
          arrivalRate: 10
      ensure:
        thresholds:
          - "http.response_time.p95": 700
          - "http.response_time.p99": 2000
        conditions:
          - expression: "http.codes.200 / http.requests > 0.95"
      plugins:
        apdex: {}
        metrics-by-endpoint:
          useOnlyRequestNames: true
    peak:
      phases:
        - duration: 60
          arrivalRate: 5
          rampTo: 10
          name: Warm up phase
        - duration: 60
          arrivalRate: 10
          rampTo: 50
          name: Ramp up to peak load
        - duration: 120
          arrivalRate: 50
          name: Sustained peak load
      plugins:
        metrics-by-endpoint:
          useOnlyRequestNames: true
      ensure:
        thresholds:
          - "http.response_time.p95": 2000
          - "http.response_time.p99": 5000
        conditions:
          - expression: "http.codes.200 / http.requests > 0.90"
scenarios:
  - name: "health check"
    weight: 1
    flow:
      - get:
          url: "/health"
          expect:
            - statusCode: 200

  - name: "list models"
    weight: 2
    flow:
      - get:
          url: "/ai/llm/v1/models"
          expect:
            - statusCode: 200
            - hasProperty: "data"

  - name: "chat completions"
    weight: 5
    flow:
      - post:
          url: "/ai/llm/v1/chat/completions"
          json:
            model: "gpt-4o-mini"
            messages:
              - role: "user"
                content: "Say hello in one word."
            max_tokens: 50
          expect:
            - statusCode: 200
            - hasProperty: "choices"
      - think: 1

  - name: "embeddings"
    weight: 2
    flow:
      - post:
          url: "/ai/llm/v1/embeddings"
          json:
            model: "text-embedding-ada-002"
            input: "Load test sample text for embeddings."
          expect:
            - statusCode: 200
            - hasProperty: "data"
      - think: 1

  - name: "upload files"
    weight: 1
    flow:
      - post:
          url: "/ai/llm/v1/files"
          contentType: "multipart/form-data"
          formData:
            file: "@{{ $env.FILE_PATH }}"
            purpose: "general"
          expect:
            - statusCode: 200
